{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPa0RDd7nBiKQMeRqvU6nfi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GregoryG3/Thesis/blob/main/Initialization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Initialization steps\n",
        "\n"
      ],
      "metadata": {
        "id": "7tMA5FMnbzsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GITHUB"
      ],
      "metadata": {
        "id": "AzoPdyj2d8Pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "username = 'GregoryG3'\n",
        "repository = 'Thesis'\n",
        "git_token = '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'"
      ],
      "metadata": {
        "id": "1zrX10zad7-j"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://{git_token}@github.com/{username}/{repository}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIUJigFPez_9",
        "outputId": "ae7e3772-a104-4749-b796-886c7d5605dd"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Thesis'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 14 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (14/14), 1.88 MiB | 8.07 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {repository}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF0FmH2Xe8QF",
        "outputId": "dd31366f-b5cc-49cd-f0ce-23cd98da7e51"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Thesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls -a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arzhZcOOfC6n",
        "outputId": "3224d527-7c1e-4e72-d82e-be2a6931531c"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34m.\u001b[0m/  \u001b[01;34m..\u001b[0m/  EDA_wstepna_analiza.ipynb  \u001b[01;34m.git\u001b[0m/  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Commends:"
      ],
      "metadata": {
        "id": "qdbW_vSkfPis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWU9xyeFfNSL",
        "outputId": "16966665-dff5-4941-f199-486b115273e0"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Modified Thesis notebok - ...\""
      ],
      "metadata": {
        "id": "pAYXbDuHfRIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you are satisfied with your work and want to save it, you can simply push your commits to GitHub"
      ],
      "metadata": {
        "id": "FqI0h97Ffbc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !git push"
      ],
      "metadata": {
        "id": "Zm_0JjCtfXQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries"
      ],
      "metadata": {
        "id": "Zdz0zKEGbxdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "from os.path import join\n"
      ],
      "metadata": {
        "id": "eBdagiGk7leK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Google drive"
      ],
      "metadata": {
        "id": "VyantTM9cV0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWXoIpLX9QSu",
        "outputId": "2b08022e-b3d6-492c-e1c7-fefceed112d6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "yuapH-tJ_1lU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_DIR = \"/content/drive/MyDrive/Thesis/Dataset\"\n",
        "RAW_DIR = join(PROJECT_DIR, \"raw\")\n",
        "PROCESSED_DIR = join(PROJECT_DIR, \"processed\")"
      ],
      "metadata": {
        "id": "kMQAEWWG7mGl"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_columns_total = [\"bikeReasons\", \"vehiclesOwned\",\n",
        "                     \"whyBiking\", \"introSelection\"]\n",
        "dict_columns_total = [\"berlinTraffic\",\n",
        "                     \"motivationalFactors\",\n",
        "                     \"transportRatings\",\n",
        "                     \"responsible\",\n",
        "                     \"climateTraffic\",\n",
        "                     \"sharingConditions\",\n",
        "                     \"sharingModes\",\n",
        "                     \"saveSpace\",\n",
        "                     \"annoyingPeople\"]"
      ],
      "metadata": {
        "id": "aPDk60ueB6M_"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(filename):\n",
        "    \"\"\"Load raw data file and create dataframes for the ratings and the profiles\n",
        "        Arguments:\n",
        "        filename {str} -- filename of the raw data used\n",
        "    \"\"\"\n",
        "\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logger.info('Preprocessing data')\n",
        "    data = json.load(open(join(RAW_DIR, filename), \"rb\"))\n",
        "    profiles_list = []\n",
        "    data_df = pd.DataFrame()\n",
        "    logger.info('Raw data contains %s entries', len(data))\n",
        "\n",
        "    # Spliting to 2 data frame - ratings and profiles\n",
        "    for data_point in data:\n",
        "        rating_df = pd.DataFrame(data_point[\"ratings\"])\n",
        "        rating_df[\"sessionID\"] = data_point[\"profile\"][\"sessionID\"]\n",
        "        rating_df = rating_df.reset_index(level=0)\n",
        "        data_df = pd.concat([data_df, rating_df], ignore_index=True, sort=False)\n",
        "        profiles_list.append(data_point[\"profile\"])\n",
        "    profiles_df = pd.DataFrame(profiles_list).set_index(\"sessionID\")\n",
        "\n",
        "    logger.info(\"Drop 'isTosAccepted' column\")\n",
        "    # Drop columns - I checked that everybody accpet the Privacy Policy\n",
        "    columns_to_drop = [\"isTosAccepted\"] # \"berlinTraffic_0\"\n",
        "    profiles_df = profiles_df.drop(columns_to_drop, axis=1)\n",
        "\n",
        "\n",
        "    dict_columns = [x for x in dict_columns_total if x in profiles_df.columns]\n",
        "    list_columns = [x for x in list_columns_total if x in profiles_df.columns]\n",
        "    logger.info(\"Split dictionary-type columns into separate columns\")\n",
        "    # iterates through dictionary-type columns splitting each into separate columns\n",
        "    for col in dict_columns:\n",
        "        new_columns = profiles_df[col].apply(pd.Series)\n",
        "        new_columns.columns = [col + \"_\" + str(name)\n",
        "                                for name in new_columns.columns]\n",
        "        profiles_df = pd.concat([profiles_df.drop([col], axis=1),\n",
        "                                  new_columns],\n",
        "                                axis=1)\n",
        "    logger.info(\"Split list-type columns into separate columns\")\n",
        "    # iterates through list-type columns splitting each into separate columns\n",
        "    for col in list_columns:\n",
        "        for subject in profiles_df.index:\n",
        "            answers = profiles_df.loc[subject][col]\n",
        "            counts = pd.Series(\n",
        "                      answers,\n",
        "                      dtype=\"object\").value_counts().rename(\n",
        "                                                    subject).add_prefix(\n",
        "                                                              col + \"_\")\n",
        "            for i in counts.index:\n",
        "                if i not in profiles_df.columns:\n",
        "                    profiles_df[i] = np.nan\n",
        "            copy = profiles_df.loc[subject].copy()\n",
        "            copy[counts.index] = counts\n",
        "            profiles_df.loc[subject] = copy\n",
        "        profiles_df = profiles_df.drop(col, axis=1)\n",
        "\n",
        "    logger.info(\"Save to csv\")\n",
        "    profiles_df.to_csv(join(PROCESSED_DIR, \"profiles_df_without_state.csv\"))\n",
        "    data_df.to_csv(join(PROCESSED_DIR, \"ratings.csv\"), index=False)\n"
      ],
      "metadata": {
        "id": "A3BWNDHnvff3"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\" Runs data processing scripts to turn raw data from (../raw) into\n",
        "        cleaned data ready to be analyzed (saved in ../processed).\n",
        "    \"\"\"\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logging.getLogger().setLevel(logging.INFO)\n",
        "    logger.info('Making final data set from raw data')\n",
        "\n",
        "    filename = \"SurveyResults_200414.json\"\n",
        "    preprocessing(filename)"
      ],
      "metadata": {
        "id": "RmqXJMzRwaSU"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run main preprocessing:"
      ],
      "metadata": {
        "id": "0aHBbXcW4Juu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "KKT1Jy0Aw8Nq"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert zipcode to specific district (only Berlin) and state"
      ],
      "metadata": {
        "id": "RX0REIgi4WTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zipcode_convert():\n",
        "    profiles_df = pd.read_csv(join(PROCESSED_DIR, \"profiles_df_without_state.csv\"),\n",
        "                            low_memory=False)\n",
        "    plz2district = pd.read_csv(join(PROJECT_DIR, \"external/Postcode_BerlinDistricts.csv\"),\n",
        "                            index_col=0, sep=';')\n",
        "    germany_states = pd.read_csv(join(PROJECT_DIR, \"external/Germany_complete_gis_info.csv\"),\n",
        "                            index_col=0, sep=';')\n",
        "\n",
        "    zipcode_to_district = plz2district['Stadtteil'].to_dict()\n",
        "    profiles_df['district'] = profiles_df['zipcode'].map(zipcode_to_district)\n",
        "\n",
        "    zipcode_to_state = germany_states['State'].to_dict()\n",
        "    district_col_index = profiles_df.columns.get_loc('district')\n",
        "    profiles_df.insert(district_col_index + 1, 'state', profiles_df['zipcode'].map(zipcode_to_state))\n",
        "\n",
        "    profiles_df.to_csv(join(PROCESSED_DIR, \"profiles_df.csv\"))"
      ],
      "metadata": {
        "id": "0S5CtfbGBIxh"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    zipcode_convert()"
      ],
      "metadata": {
        "id": "A9mVsGJsjh4t"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yishxVIIQ4XG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}